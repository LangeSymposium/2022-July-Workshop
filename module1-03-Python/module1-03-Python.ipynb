{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5aeab52",
   "metadata": {},
   "source": [
    "# Python for Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1380993c",
   "metadata": {},
   "source": [
    "## Why Python?\n",
    "\n",
    "- Python: general-purpose programming language $\\rightarrow$ large user base from diverse disciplines\n",
    "    - cf. R: specializes in statistical computing/data analytics (more domain-specific)\n",
    "Unlike R, which specializes in statistical computing/data analytics (more domain-specific)\n",
    "\n",
    "    - Rich pool of scientific libraries with strong community support\n",
    "    - Many useful libraries beyond scientific computing \n",
    "        - Natural to directly utilize scientific computing results in diverse applications such as image processing, natural language processing, gaming, etc.\n",
    "    - Disciplines like machine learning: \n",
    "        - Python became the de facto standard language in many companies, and you may be required to use it sometimes. \n",
    "        - tensorflow, pytorch for deep learning, etc. and they are all in Python.\n",
    "\n",
    "### Scientific Python (SciPy) Ecosystem\n",
    "\n",
    "Libraries are important characteristic of how Python works: each application has its libraries. For scientific computing, one can use a combination of the following packages that meets the need. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| Package | Description | Logo |\n",
    "|:---:|:---|:---:|\n",
    "| __Numpy__ | Numerical arrays | <img src=\"https://numpy.org/doc/stable/_static/numpylogo.svg\" width=\"300\"/> |\n",
    "| Scipy | User-friendly and efficient numerical routines:<br> numerical integration, interpolation, optimization, linear algebra, and statistics | <img src=\"https://scipy.org/images/logo.svg\" width=\"200\"/> |\n",
    "| __Jupyter Notebook__ | Interactive programming environment | <img src=\"https://jupyter.org/assets/homepage/main-logo.svg\" width=\"200\"/> |\n",
    "| __Matplotlib__ | Plotting | <img src=\"https://matplotlib.org/_static/logo2_compressed.svg\" width=\"300\"/>|\n",
    "| __Pandas__ | Data analytics <br> R-like data frames | <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Pandas_logo.svg/1024px-Pandas_logo.svg.png\" width=\"300\"/> |\n",
    "| Scikit-learn | Machine learning | <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Scikit_learn_logo_small.svg/2880px-Scikit_learn_logo_small.svg.png\" width=\"300\"/> | \n",
    "\n",
    "All the packages above are included in the [Anaconda distribution](https://www.anaconda.com/products/distribution) of Python. If you download Anaconda, it comes with all the useful scientific programming packages. Packages used in this workshop are in bold.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4813ef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "print(IPython.sys_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c9a9d8",
   "metadata": {},
   "source": [
    "## Before We move on...\n",
    "\n",
    "We have limited resources for each user on the cloud. Don't forget to shut down the kernels you are not using. \n",
    "\n",
    "![](shutdown_kernel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5beedf",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "Pandas is a Python library for working with datasets. It supports data frame structure like in R. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c509007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pandas library\n",
    "import pandas as pd\n",
    "# we also load numpy for array computation for convenience\n",
    "import numpy as np\n",
    "import platform\n",
    "mimic_path =  \"/Users/huazhou/Desktop/mimic-iv-1.0\" if platform.uname().node == \"RELMDOMFAC30610\" else \"/home/shared/1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f89e8bc",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f190a22b",
   "metadata": {},
   "source": [
    "Let's load `icustays.csv.gz` file as a pandas data frame. We need to predetermine the columnes with date-time values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fb15c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "icustays_df = pd.read_csv(mimic_path + \"/icu/icustays.csv.gz\", parse_dates=[\"intime\", \"outtime\"])\n",
    "print(icustays_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac4dbce-1b22-4cdb-bd47-33839dbb617d",
   "metadata": {},
   "source": [
    "You may press `Shift-Tab` to see the function documentation interactively, or typing `?pd.read_csv` in the code cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b258da",
   "metadata": {},
   "outputs": [],
   "source": [
    "icustays_df.__class__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a0d7a2-42df-4a55-bfb5-ebc3b685b5b1",
   "metadata": {},
   "source": [
    "The variable read in is an instance of `DataFrame`. Let's talk a little bit about what this means. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e62fab6-52b4-4cd7-8dba-ccd1ff9aa3ad",
   "metadata": {},
   "source": [
    "#### Note: Object-Oriented Programming\n",
    "\n",
    "Python has built-in object-oriented programming (OOP) support. The OOP paradigm is based on \"objects\", which is bundled with data representing properties of the object and code in the form of method. \n",
    "\n",
    "- __Class__: defines data format (attributes) and available procdeures (methods) for an object. `DataFrame`.\n",
    "- __Object__: An instance of a class. `icustays_df`. \n",
    "- __Attributes__: Properties like column names, number of rows, number of columns, etc. __syntax: `df.attribute`__\n",
    "- __Methods__: \"Actions\" (or procedures/functions) applied to or performed on the object. __syntax: `df.method(arg1, arg2, etc.)`__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9da902",
   "metadata": {},
   "source": [
    "Now `admissions.csv.gz`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d92363",
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions_df = pd.read_csv(mimic_path + \"/core/admissions.csv.gz\",\n",
    "                           parse_dates = [\"admittime\", \"dischtime\", \"deathtime\", \"edregtime\", \"edouttime\"])\n",
    "print(admissions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4646d9f",
   "metadata": {},
   "source": [
    "And `patients.csv.gz`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6393a23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_df = pd.read_csv(mimic_path + \"/core/patients.csv.gz\")\n",
    "print(patients_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e6f7d5",
   "metadata": {},
   "source": [
    "For `chartevents_filtered_itemid.csv.gz`, we learn how to read in only selected columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5794f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075d4dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "chartevents_df = pd.read_csv(\n",
    "    mimic_path + \"/icu/chartevents_filtered_itemid.csv.gz\",\n",
    "    usecols = [\"stay_id\", \"itemid\", \"charttime\", \"valuenum\"],\n",
    "    dtype = {\"stay_id\" : np.float64, \"itemid\" : np.float64, \"charttime\" : \"str\", \"valuenum\" : np.float64},\n",
    "    parse_dates = [\"charttime\"]\n",
    "    )\n",
    "end = timer()\n",
    "print(\"Elapsed time: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a043a839",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chartevents_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c905204c",
   "metadata": {},
   "source": [
    "For filtering, we can use the `query` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb380953",
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_df.query(\"stay_id == 30600691 and itemid == 220045\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7413459a",
   "metadata": {},
   "source": [
    "And for plotting, we use the package `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004ae9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467785e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    chartevents_df.query(\"stay_id == 30600691 and itemid == 220045\").\n",
    "        plot.scatter(x=\"charttime\", y=\"valuenum\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b6f7d1",
   "metadata": {},
   "source": [
    "#### Note: Method Chaining\n",
    "One may use method chaining for linearizing method calls, as above. As the dot operator(`.`) is evaluated from left to right, one may \"chain\" another method call or attribute access right after obtaining the result of the previous method call or attribute access. This is a \"pythonic\" way of avoiding nested calls.\n",
    "\n",
    "One limitation is that we can only do this for methods or attributes of a class. In this case, `print()` is not a method of `DataFrame`, we cannot chain `print` as what we did in R. One may use [`pandas.DataFrame.pipe()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pipe.html) method for such operations. \n",
    "There are packages that implement pipe by overloading other operator (e.g., the bitwise or (`|`) operator). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b8032a",
   "metadata": {},
   "source": [
    "## Target cohort (from R section)\n",
    "\n",
    "Let's continue on with the task we did with R. We aim to develop a predictive model, which computes the chance of dying within 30 days of ICU stay `intime` based on baseline features  \n",
    "- `first_careunit`  \n",
    "- `age` at `intime`  \n",
    "- `gender`  \n",
    "- `ethnicity`  \n",
    "- first measurement of the following vitals since ICU stay `intime`  \n",
    "    - 220045 for heart rate   \n",
    "    - 223761 for Temperature Fahrenheit  \n",
    "\n",
    "\n",
    "We restrict to the first ICU stays of each unique patient. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bcb299",
   "metadata": {},
   "source": [
    "## Wrangling and merging data frames\n",
    "\n",
    "Our stragegy is\n",
    "\n",
    "1. Identify and keep the first ICU stay of each patient. \n",
    "\n",
    "2. Identify and keep the first vital measurements during the first ICU stay of each patient.\n",
    "\n",
    "3. Join four data frames into a single data frame.\n",
    "\n",
    "Important data wrangling concepts: group_by, sort, slice, joins, and pivot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9fe947",
   "metadata": {},
   "source": [
    "### Step 1: restrict to the first ICU stay of each patient\n",
    "\n",
    "`icustays_df` has 76,540 rows, which is reduced to 53,150 unique ICU stays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c825e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "icustays_df_1ststay = (icustays_df.sort_values([\"subject_id\", \"intime\"]).\n",
    "                       groupby(\"subject_id\").\n",
    "                       head(1)) # head() is much faster than slice_head(n) in dplyr\n",
    "print(icustays_df_1ststay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fab110",
   "metadata": {},
   "source": [
    "### Step 2: restrict to the first vital measurements during the ICU stay\n",
    "\n",
    "Key data wrangling concepts: selecting columns, left_join, right_join, group_by, sort, pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e3364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_df_1ststay = (\n",
    "    chartevents_df.\n",
    "    merge(\n",
    "        icustays_df_1ststay[[\"stay_id\", \"intime\", \"outtime\"]],\n",
    "        how = \"right\",\n",
    "        on = \"stay_id\"). # 15738363 rows\n",
    "    query(\"charttime >= intime and charttime <= outtime\"). # 15700234 rows\n",
    "    sort_values([\"stay_id\", \"itemid\", \"charttime\"]).\n",
    "    groupby([\"stay_id\", \"itemid\"]).\n",
    "    head(1). # 263332 rows\n",
    "    drop([\"charttime\", \"intime\", \"outtime\"], axis=\"columns\"). # remove unnecessary columns\n",
    "    astype({\"itemid\": str}). # change it to string for easier renaming\n",
    "    pivot(index=\"stay_id\", columns=\"itemid\", values=\"valuenum\").\n",
    "    rename(columns={\"220045.0\": \"heart_rate\",\n",
    "            \"223761.0\": \"temp_f\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb66eaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chartevents_df_1ststay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789da434",
   "metadata": {},
   "source": [
    "### Step 3: merge DataFrames\n",
    "\n",
    "New data wrangling concept: mutate. Pandas equivalent is `assign`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006c49f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_icu_cohort = (\n",
    "    icustays_df_1ststay.\n",
    "    # merge dataframes\n",
    "    merge(admissions_df, on=[\"subject_id\", \"hadm_id\"], how=\"left\").\n",
    "    merge(patients_df, on=[\"subject_id\"], how=\"left\").\n",
    "    merge(chartevents_df_1ststay, on=[\"stay_id\"], how=\"left\").\n",
    "    # age_intime is the age at the ICU stay intime\n",
    "    assign(age_intime = lambda df: \n",
    "           df[\"anchor_age\"] + df[\"intime\"].map(lambda x : x.year) - df[\"anchor_year\"]).\n",
    "    # whether the patient died within 30 days of ICU stay intime\n",
    "    assign(hadm_to_death = lambda df: \n",
    "           np.where(np.isnan(df[\"deathtime\"]), \n",
    "                    np.inf, \n",
    "                    (df[\"deathtime\"] - df[\"intime\"]).dt.total_seconds())).\n",
    "    assign(thirty_day_mort = lambda df: df[\"hadm_to_death\"] <= 2592000)   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c386e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_icu_cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f77efa3",
   "metadata": {},
   "source": [
    "## Data visualization\n",
    "\n",
    "\n",
    "Remember we want to model: \n",
    "\n",
    "thirty_day_mort ~ first_careunit + age_intime + gender + ethnicity + heart_rate + bp_mean + bp_syst + temp_f + resp_rate\n",
    "\n",
    "Let's start with a numerical summary of variables of interest.\n",
    "\n",
    "For numerical column, we can obtain mean, standard deviation, and quartiles using the method `describe()`. For a categorical column, we obtain number of unique values, value with the most appearance, and its frequency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e05a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    mimic_icu_cohort[[\"first_careunit\", \n",
    "        \"gender\", \n",
    "        \"ethnicity\", \n",
    "        \"age_intime\", \n",
    "        \"heart_rate\", \n",
    "        \"temp_f\"]].\n",
    "    describe(include=\"all\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc4ddcd",
   "metadata": {},
   "source": [
    "Do you spot anything unusual?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc85b3b4",
   "metadata": {},
   "source": [
    "To obtain counts of each value for categorical column, we use `value_counts()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9e5899",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_icu_cohort[\"first_careunit\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba82f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_icu_cohort[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf2337",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_icu_cohort[\"ethnicity\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7d115c",
   "metadata": {},
   "source": [
    "### Univariate summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abf1436",
   "metadata": {},
   "source": [
    "Before we start, let's import the `seaborn` package for styling the figures a little bit (looking like ggplot2). This package is for statistical data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250f373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d39c19",
   "metadata": {},
   "source": [
    "Bar plot of `first_careunit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0e306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_icu_cohort[\"first_careunit\"].value_counts(sort=False).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64807bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_icu_cohort[\"age_intime\"].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfd4d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_icu_cohort[\"age_intime\"].plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adff8023",
   "metadata": {},
   "source": [
    "Histogram and boxplot of `age_intime`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a337bf",
   "metadata": {},
   "source": [
    "#### Exercises\n",
    "\n",
    "1. Summarize discrete variables: `gender`, `ethnicity`.  \n",
    "2. Summarize continuous variables: `heart_rate`, `temp_f`.\n",
    "3. Is there anything unusual about `temp_f`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fb0147",
   "metadata": {},
   "source": [
    "### Bivariate summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef10fa93",
   "metadata": {},
   "source": [
    "Tally of `thirty_day_mort` vs `first_careunit`. \n",
    "\n",
    "We need to be a little more verbose for plotting frequencies in stacked barplot in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beee688",
   "metadata": {},
   "outputs": [],
   "source": [
    "(mimic_icu_cohort.\n",
    "     groupby(\"first_careunit\")[\"thirty_day_mort\"].value_counts().\n",
    "     unstack(\"thirty_day_mort\").iloc[:, ::-1]. # reversing column order to make True come first\n",
    " plot.bar(stacked=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f718e73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(mimic_icu_cohort.\n",
    "     groupby(\"first_careunit\")[\"thirty_day_mort\"].value_counts(normalize=True).\n",
    "     unstack(\"thirty_day_mort\").iloc[:, ::-1].\n",
    "     plot.bar(stacked=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9d472c",
   "metadata": {},
   "source": [
    "Tally of `thirty_day_mort` vs `gender`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cfec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "(mimic_icu_cohort.\n",
    "     groupby(\"gender\")[\"thirty_day_mort\"].value_counts(normalize=False).\n",
    "     unstack(\"thirty_day_mort\").iloc[:, ::-1].\n",
    "     plot.bar(stacked=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecbb45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(mimic_icu_cohort.\n",
    "     groupby(\"gender\")[\"thirty_day_mort\"].value_counts(normalize=True).\n",
    "     unstack(\"thirty_day_mort\").iloc[:, ::-1].\n",
    "     plot.bar(stacked=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f18642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_icu_cohort.groupby(\"gender\")[\"thirty_day_mort\"].value_counts(normalize=True).unstack(\"thirty_day_mort\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb607182",
   "metadata": {},
   "source": [
    "#### Exercises\n",
    "\n",
    "1. Graphical summaries of `thirty_day_mort` vs other predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b81545-8b43-4d5b-9954-4391b3a09b09",
   "metadata": {},
   "source": [
    "## Pros and Cons of Python for Data Science\n",
    "\n",
    "\n",
    "__Pros__: \n",
    "- General purpose $\\rightarrow$ can directly use the data analysis result to different disciplines\n",
    "- Wide user base $\\rightarrow$ rich package ecosystem\n",
    "- Readable and fast\n",
    "\n",
    "__Cons__: \n",
    "- Less statistical analysis packages\n",
    "- Libraries may be more hard to understand\n",
    "- Visualization is more convoluted than R"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
